{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:53.193920Z","iopub.status.busy":"2024-03-26T14:16:53.193499Z","iopub.status.idle":"2024-03-26T14:16:53.198717Z","shell.execute_reply":"2024-03-26T14:16:53.197511Z","shell.execute_reply.started":"2024-03-26T14:16:53.193888Z"},"id":"FQaxwZtSCcRn","trusted":true},"outputs":[],"source":["# !pip install tqdm"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:53.201274Z","iopub.status.busy":"2024-03-26T14:16:53.200829Z","iopub.status.idle":"2024-03-26T14:16:53.242499Z","shell.execute_reply":"2024-03-26T14:16:53.241417Z","shell.execute_reply.started":"2024-03-26T14:16:53.201243Z"},"id":"HWZBGOIC_EDS","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/mnt/nvme-Samsung_SSD_970_EVO_1TB_S5H9NS0NA91427J-part2/TU/Onedrive/Robotics/CS4240 Deep learning/Project/StreetView-CropType/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import random\n","from PIL import Image\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","from collections import Counter\n","from transformers import ViTForImageClassification\n","from scipy import stats\n","\n","\n","\n","label_to_int = {'Goed': 0, 'Matig': 1, 'Redelijk': 2, 'Slecht': 3, 'Zeer_Slecht': 4, 'Dood': 5}\n","\n","class CustomImageDataset1(Dataset):\n","    def __init__(self, images, labels, transforms=None, samples_per_class=None):\n","        self.images = images\n","        self.labels = [label_to_int[label] for label in labels]\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.images[idx])\n","        label = self.labels[idx]\n","\n","        # Remove top 30% of the image\n","        width, height = image.size\n","        image = image.crop((0, height * 0.3, width, height))\n","\n","        if self.transforms:\n","            image = self.transforms(image)\n","\n","        return image, label\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, images, labels, transforms=None, sampling_factors=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transforms = transforms\n","        self.sampling_factors = sampling_factors if sampling_factors is not None else {label: 1 for label in set(labels)}\n","\n","    def __len__(self):\n","        # Calculate total length considering sampling factors\n","        total_length = 0\n","        for label in self.labels:\n","            total_length += self.sampling_factors[label]\n","        return total_length\n","\n","    def __getitem__(self, idx):\n","        # Find the actual image index based on the sampling factor\n","        actual_idx = idx\n","        for i, label in enumerate(self.labels):\n","            if actual_idx < self.sampling_factors[label]:\n","                break\n","            actual_idx -= self.sampling_factors[label]\n","\n","\n","        image = Image.open(self.images[i])\n","        label = self.labels[i]\n","\n","        # Remove top 30% of the image\n","        width, height = image.size\n","        image = image.crop((0, height * 0.3, width, height))\n","\n","        # Process image\n","        if self.transforms:\n","            image = self.transforms(image)\n","\n","        return image, label_to_int[label]\n","\n","def load_images(folder_path):\n","    print(\"Loading images...\")\n","\n","    images = []\n","    labels = []\n","    for class_folder in os.listdir(folder_path):\n","        class_path = os.path.join(folder_path, class_folder)\n","        for img_file in os.listdir(class_path):\n","            img_path = os.path.join(class_path, img_file)\n","            images.append(img_path)\n","            labels.append(class_folder)\n","    print(\"Total images loaded:\", len(images))\n","    return images, labels\n","\n","def split_dataset(images, labels, train_ratio=0.6, val_ratio=0.2):\n","    # Split dataset into train, validation, and test\n","    print(\"Splitting dataset...\")\n","    dataset = list(zip(images, labels))\n","    random.shuffle(dataset)\n","    train_size = int(len(dataset) * train_ratio)\n","    val_size = int(len(dataset) * val_ratio)\n","    train_set = dataset[:train_size]\n","    val_set = dataset[train_size:train_size + val_size]\n","    test_set = dataset[train_size + val_size:]\n","    print(f\"Dataset split into {len(train_set)} training, {len(val_set)} validation, and {len(test_set)} test images.\")\n","    return train_set, val_set, test_set\n","\n","def count_class_distribution(dataset):\n","    class_counts = {}\n","    for _, label in dataset:\n","        class_counts[label] = class_counts.get(label, 0) + 1\n","    return class_counts\n","\n","def calculate_sampling_factors(train_set):\n","    label_counts = Counter(label for _, label in train_set)\n","    min_samples = min(label_counts.values())\n","\n","    # Calculate sampling factor for each class\n","    sampling_factors = {label: round(min_samples / count*1000) for label, count in label_counts.items()}\n","    return sampling_factors\n","\n","def create_dataloaders(train_set, val_set, test_set, sampling_factors, batch_size):\n","    # Define transformations\n","    print(\"Creating dataloaders...\")\n","\n","    train_transforms = transforms.Compose([\n","        transforms.RandomCrop(224),  # Specify size\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","    val_test_transforms = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    train_dataset = CustomImageDataset([i[0] for i in train_set], [i[1] for i in train_set], transforms=train_transforms, sampling_factors=sampling_factors)\n","    val_dataset = CustomImageDataset([i[0] for i in val_set], [i[1] for i in val_set], transforms=val_test_transforms)\n","    test_dataset = CustomImageDataset([i[0] for i in test_set], [i[1] for i in test_set], transforms=val_test_transforms)\n","    # print('Dataset', train_dataset[0])\n","    # Create dataloaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    print(\"Dataloaders created.\")\n","    print(len(train_loader), len(val_loader), len(test_loader))\n","    return train_loader, val_loader, test_loader\n","\n","def calculate_samples_per_class(class_distribution):\n","    min_count = min(class_distribution.values())\n","    print(\"Min count training: \"+str(min_count))\n","    samples_per_class = {label_to_int[cls]: round(min_count / count*1000) for cls, count in class_distribution.items()}\n","    print(\"samples per class: \")\n","    print(samples_per_class)\n","    return samples_per_class\n","\n","\n","\n","def load_data(folder1):\n","    images, labels = load_images(folder1)\n","    train_set, val_set, test_set = split_dataset(images, labels)\n","\n","    # Print class distribution\n","    train_class_distribution = count_class_distribution(train_set)\n","    val_class_distribution = count_class_distribution(val_set)\n","    test_class_distribution = count_class_distribution(test_set)\n","\n","    print(\"Training set class distribution:\", train_class_distribution)\n","    print(\"Validation set class distribution:\", val_class_distribution)\n","    print(\"Test set class distribution:\", test_class_distribution)\n","\n","    sampling_factors = calculate_sampling_factors(train_set)\n","#     sampling_factors = {'rice': 1, 'other': 2, 'sugarcane': 6, 'cassava': 12, 'maize': 10}\n","#     sampling_factors = {'Goed': 7, 'Matig': 7, 'Redelijk': 7, 'Slecht': 7, 'Zeer Slecht': 7}\n","#     sampling_factors = {'goed': 10, 'matige': 10, 'Redelijk': 10, 'slecht': 10, 'Zeer_slecht': 10, 'dood': 10}\n","    print('Sampling factors: ', sampling_factors)\n","    train_loader, val_loader, test_loader = create_dataloaders(train_set, val_set, test_set, sampling_factors, batch_size=8)\n","\n","    return train_loader, val_loader, test_loader"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:53.336472Z","iopub.status.busy":"2024-03-26T14:16:53.335425Z","iopub.status.idle":"2024-03-26T14:16:53.372000Z","shell.execute_reply":"2024-03-26T14:16:53.370636Z","shell.execute_reply.started":"2024-03-26T14:16:53.336434Z"},"id":"2Iz78yn6_S65","trusted":true},"outputs":[],"source":["def extract_patches(image, patch_size, stride):\n","    patches = []\n","    c, height, width = image.size()\n","\n","    for y in range(0, height - patch_size[1] + 1, stride):\n","        for x in range(0, width - patch_size[0] + 1, stride):\n","            patch = image[:, y:y + patch_size[1], x:x + patch_size[0]]\n","            patches.append(patch)\n","\n","    return patches\n","\n","def train_one_epoch(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    total_correct = 0\n","    total_samples = 0\n","    all_labels = []\n","    all_preds = []\n","\n","    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n","    for images, labels in progress_bar:\n","\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","\n","        # Forward pass\n","        outputs = model(images)\n","\n","        #For ViT\n","        logits = outputs.logits  # Extract the logits\n","        loss = criterion(logits, labels)\n","\n","        # loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Statistics\n","        # _, predicted = torch.max(outputs, 1)\n","        _, predicted = torch.max(outputs.logits, 1)\n","\n","        correct = (predicted == labels).sum().item()\n","        progress_bar.set_postfix(loss=loss.item(), accuracy=correct/len(labels))\n","\n","        total_loss += loss.item()\n","        total_correct += correct\n","        total_samples += labels.size(0)\n","\n","        # For F1 score calculation\n","        all_labels.extend(labels.cpu().numpy())\n","        all_preds.extend(predicted.cpu().numpy())\n","\n","    avg_loss = total_loss / len(train_loader)\n","    accuracy = total_correct / total_samples\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n","\n","    return avg_loss, accuracy, f1, per_class_f1\n","\n","\n","\n","def validate_or_test(model, loader, criterion, device, patch_size, stride, model_name, epoch, desc='Val'):\n","    model.eval()\n","    total_loss = 0\n","    total_samples = 0\n","    all_labels = []\n","    all_preds = []\n","\n","    progress_bar = tqdm(loader, desc=desc, leave=False)\n","    with torch.no_grad():\n","        for images, labels in progress_bar:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            batch_preds = []\n","\n","            for image in images:\n","                # # Apply sliding window approach\n","                # patches = extract_patches(image, patch_size, stride)\n","                # patches = torch.stack(patches).to(device)\n","\n","                # # Aggregate predictions for each patch\n","                # patch_outputs = model(patches)\n","                # logits = patch_outputs.logits  # Extract the logits\n","                # patch_predictions = torch.mean(logits, dim=0)\n","                # patch_predictions = torch.mean(patch_outputs, dim=0)\n","                # batch_preds.append(patch_predictions)\n","\n","                # Calculate the mode of the patch predictions\n","\n","                patches = extract_patches(image, patch_size, stride)\n","                patches = torch.stack(patches).to(device)\n","\n","                # Aggregate predictions for each patch\n","                patch_outputs = model(patches)\n","                logits = patch_outputs.logits  # Extract the logits\n","\n","                # Calculate mode for each patch prediction\n","                modes, _ = torch.mode(logits, dim=0)\n","                batch_preds.append(modes)\n","\n","            # print(batch_preds)\n","            batch_preds = torch.stack(batch_preds)\n","            loss = criterion(batch_preds, labels)\n","            total_loss += loss.item()\n","\n","            _, predicted = torch.max(batch_preds, 1)\n","            total_samples += labels.size(0)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(predicted.cpu().numpy())\n","\n","            # Update progress bar\n","            progress_bar.set_postfix(loss=loss.item())\n","\n","    avg_loss = total_loss / len(loader)\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n","\n","    conf_matrix = confusion_matrix(all_labels, all_preds)\n","    conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n","\n","    # Plot confusion matrix\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(conf_matrix_percentage, annot=True, fmt='g', cmap='Blues')\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.title('Confusion Matrix')\n","    plt.savefig(outputRoot+f'{model_name}_epoch_{epoch}.png')\n","    plt.show()\n","    return avg_loss, accuracy, f1, per_class_f1\n","\n","def train_and_evaluate(model, train_loader, val_loader, test_loader, model_name, num_epochs=5, patch_size=(224, 224), stride=30):\n","    # Criterion, Optimizer, and Scheduler\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=2e-4)\n","    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n","\n","    global best_val_f1\n","    global best_model_weights\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    for epoch in range(num_epochs):\n","        train_loss, train_accuracy, train_f1, train_f1_per_class = train_one_epoch(model, train_loader, criterion, optimizer, device)\n","        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1:.4f}')\n","        print(f'Train F1 Score Per Class ', train_f1_per_class)\n","\n","        val_loss, val_accuracy, val_f1, val_f1_per_class = validate_or_test(model, val_loader, criterion, device, patch_size, stride, model_name, epoch, desc='Val')\n","        print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}')\n","        print(f'Val F1 Score Per Class ', val_f1_per_class)\n","        if val_f1 > best_val_f1:\n","            best_val_f1 = val_f1\n","            best_model_weights = model.state_dict()  # Save the best model weights\n","\n","        # Save intermediate model weights\n","        torch.save(model.state_dict(), outputRoot+f'{model_name}_epoch_{epoch}.pth')\n","\n","        scheduler.step()\n","\n","\n","    test_loss, test_accuracy, test_f1, test_f1_per_class = validate_or_test(model, test_loader, criterion, device, patch_size, model_name, 'end', stride, desc='Test')\n","    print(f'Test Loss: {test_loss:.3f}, Accuracy: {test_accuracy:.3f}, F1 Score: {test_f1:.3f}, F1 Score Per Class [{test_f1_per_class[0]:.3f}')\n","    print(f'Test F1 Score Per Class ', test_f1_per_class)\n","\n","    # After training is complete, load the best model weights\n","    model.load_state_dict(best_model_weights)\n","\n","    # Save the best model weights\n","    torch.save(model.state_dict(), outputRoot+f'{model_name}.pth')\n","    return model"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-26T14:16:53.375923Z","iopub.status.busy":"2024-03-26T14:16:53.374651Z"},"id":"QsA9rp76_V9U","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading images...\n","Total images loaded: 10965\n","Splitting dataset...\n","Dataset split into 6579 training, 2193 validation, and 2193 test images.\n","Training set class distribution: {'Matig': 3047, 'Redelijk': 2561, 'Slecht': 582, 'Dood': 107, 'Zeer_Slecht': 58, 'Goed': 224}\n","Validation set class distribution: {'Matig': 1028, 'Redelijk': 859, 'Slecht': 168, 'Goed': 74, 'Zeer_Slecht': 22, 'Dood': 42}\n","Test set class distribution: {'Redelijk': 851, 'Matig': 1046, 'Slecht': 178, 'Goed': 61, 'Dood': 35, 'Zeer_Slecht': 22}\n","Sampling factors:  {'Matig': 19, 'Redelijk': 23, 'Slecht': 100, 'Dood': 542, 'Zeer_Slecht': 1000, 'Goed': 259}\n","Creating dataloaders...\n","Dataloaders created.\n","43626 275 275\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Training:   0%|          | 81/43626 [00:30<4:29:59,  2.69it/s, accuracy=0.125, loss=1.82]"]}],"source":["# Call the main function with the path to folder1\n","imagesRoot = '../Data/drive_processed_singleTree'\n","outputRoot = 'output'\n","\n","path_to_images = imagesRoot \n","train_loader, val_loader, test_loader = load_data(path_to_images)\n","\n","def load_pretrained_vit(num_labels):\n","    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=num_labels)\n","    return model\n","\n","num_classes = 6  # Adjust as per your dataset\n","num_epochs = 10\n","# Load the pretrained ResNet-50 model\n","# model = models.resnet50(pretrained=True)\n","vit_model = load_pretrained_vit(num_labels=num_classes)\n","\n","# model.fc = nn.Linear(model.fc.in_features, num_classes)\n","# Initialize best F1 score for validation\n","\n","best_val_f1 = 0.0\n","best_model_weights = None\n","model_name = 'TreesDelftV003'\n","trained_model = train_and_evaluate(vit_model, train_loader, val_loader, test_loader, model_name, num_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0CX1RLOtcYU","trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(trained_model.parameters(), lr=2e-4)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","trained_model.to(device)\n","patch_size=(224, 224)\n","stride=30\n","test_loss, test_accuracy, test_f1, test_f1_per_class = validate_or_test(trained_model, test_loader, criterion, device, patch_size, stride, desc='Test')\n","print(f'Test Loss: {test_loss:.3f}, Accuracy: {test_accuracy:.3f}, F1 Score: {test_f1:.3f}, F1 Score Per Class [{test_f1_per_class[0]:.3f}')\n","print(f'Test F1 Score Per Class ', test_f1_per_class)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4673397,"sourceId":7947562,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
